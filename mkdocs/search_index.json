{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to NNSharp\n\n\nThis is the full documentation of NNSharp which is a lightweight library for running pre-trained neural networks. The training should be done in \nKeras\n, \nTensorFlow\n, \nPytorch\n or \nSonnet\n then the weights and the network architecture should be saved into a file (json). NNSharp is able to read and run the network especially on Windows and Visual Studio. \n\n\nCurrent abilities\n\n\nNNSharp recently supports Keras models with both Tensorflow and Theano backend. The list of the supported \nKeras layers\n:\n\n\n\n\nCore layers\n: Dense, Reshape (2D), Permute, RepeatVector. \n\n\nConvolution layers\n: Conv1D, Conv2D, Cropping1D, Cropping2D. \n\n\nPooling layers\n: AveragePooling1D, AveragePooling2D, MaxPooling1D, MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D.\n\n\nActivations\n: softmax, elu, softplus, softsign, relu, tanh, sigmoid, hard_sigmoid. \n\n\nNormalization\n: BatchNormalization.\n\n\n\n\nThe \ndata format\n supports 2-dimensional data. \n\n\nThe structure of the documentation\n\n\nThe purpose of the documentation is twofold:\n\n\n\n\nAs a user guide to show how to use the package.\n\n\nProviding some further insight how the kernels work in a concise manner. Therefore developers and researchers can immediately understand what the kernel does without inspecting the code or looking for other sources on the net. This can be helpful for contributors as a developer documentation. On the other hand users can understand what to feed into the network and how to use (and construct) the output.\n\n\n\n\nThe structure of the documentation is the following:\n\n\n\n\nInstallation\n shows how to get access to the package.\n\n\nModels\n introduces the model types and methods to access information about the model like the contained layers or nodes, execution time etc.\n\n\nKeras\n shows the implemented Keras layers. Each layer introduced with its input, output and its underlying process.\n\n\nTensorFlow\n shows how to use pre-trained TensorFlow models in NNSharp.\n\n\n\n\nFuture\n\n\nIn the future the library should provide the following features:\n\n\n\n\nSupports the whole Keras API.\n\n\nSupports TensorFlow models.\n\n\nSupports PyTorch regarding neural networks.\n\n\nSupports Sonnet.\n\n\nMulti-threading for faster kernels.\n\n\nKeras-like API over TensorFlow for building, training and running networks. This requires an extended C++ API in TensorFlow and reliable compilation for Windows.\n\n\n\n\nContributions are always welcomed! For the current purposes see the \ngithub repository\n of the project.",
            "title": "Overview"
        },
        {
            "location": "/#welcome-to-nnsharp",
            "text": "This is the full documentation of NNSharp which is a lightweight library for running pre-trained neural networks. The training should be done in  Keras ,  TensorFlow ,  Pytorch  or  Sonnet  then the weights and the network architecture should be saved into a file (json). NNSharp is able to read and run the network especially on Windows and Visual Studio.",
            "title": "Welcome to NNSharp"
        },
        {
            "location": "/#current-abilities",
            "text": "NNSharp recently supports Keras models with both Tensorflow and Theano backend. The list of the supported  Keras layers :   Core layers : Dense, Reshape (2D), Permute, RepeatVector.   Convolution layers : Conv1D, Conv2D, Cropping1D, Cropping2D.   Pooling layers : AveragePooling1D, AveragePooling2D, MaxPooling1D, MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D.  Activations : softmax, elu, softplus, softsign, relu, tanh, sigmoid, hard_sigmoid.   Normalization : BatchNormalization.   The  data format  supports 2-dimensional data.",
            "title": "Current abilities"
        },
        {
            "location": "/#the-structure-of-the-documentation",
            "text": "The purpose of the documentation is twofold:   As a user guide to show how to use the package.  Providing some further insight how the kernels work in a concise manner. Therefore developers and researchers can immediately understand what the kernel does without inspecting the code or looking for other sources on the net. This can be helpful for contributors as a developer documentation. On the other hand users can understand what to feed into the network and how to use (and construct) the output.   The structure of the documentation is the following:   Installation  shows how to get access to the package.  Models  introduces the model types and methods to access information about the model like the contained layers or nodes, execution time etc.  Keras  shows the implemented Keras layers. Each layer introduced with its input, output and its underlying process.  TensorFlow  shows how to use pre-trained TensorFlow models in NNSharp.",
            "title": "The structure of the documentation"
        },
        {
            "location": "/#future",
            "text": "In the future the library should provide the following features:   Supports the whole Keras API.  Supports TensorFlow models.  Supports PyTorch regarding neural networks.  Supports Sonnet.  Multi-threading for faster kernels.  Keras-like API over TensorFlow for building, training and running networks. This requires an extended C++ API in TensorFlow and reliable compilation for Windows.   Contributions are always welcomed! For the current purposes see the  github repository  of the project.",
            "title": "Future"
        },
        {
            "location": "/install/",
            "text": "Installation\n\n\n\n\nNNSharp is available as a \nnuget package\n. It was built on Visual Studio 2015 with .NET Framework 4.5.2. The easiest way to install is to use the \nnuget package manager\n in Visual Studio. As an other option the necessary dll can be built from the source code (\ndownload link\n). The current release is the v1.1. It has only one dependency: \nNewtonsoft.Json\n.",
            "title": "Installation"
        },
        {
            "location": "/install/#installation",
            "text": "NNSharp is available as a  nuget package . It was built on Visual Studio 2015 with .NET Framework 4.5.2. The easiest way to install is to use the  nuget package manager  in Visual Studio. As an other option the necessary dll can be built from the source code ( download link ). The current release is the v1.1. It has only one dependency:  Newtonsoft.Json .",
            "title": "Installation"
        },
        {
            "location": "/models/",
            "text": "Models\n\n\nInterface: IModel\n\n\nThis is the interface for all of the models. It contains only one function which returns the structure of the model. This is important to get access to the model details.\n\n\nSequential model\n\n\n \n[source]\n \n\n\n\nThe smallest building block of the sequential model is the \nlayer\n. The layers are organised consequtively. The output of a layer is the input to the next layer.\n\n\nNNSharp architecture is based on general descriptors of the possible operations (called kernels in this context) and then it applies a compiler to get the executable model. The compilation is done when a reader function (see Keras part for example) is called. The reader function reads the descriptors, builds a model then compiles it. After compilation calculations on new date reuires to call:\n\n\nIData ExecuteNetwork(IData input)\n\n\n\nWhere IData can be a Data2D data type (or later Data3D). At the detailed descriptions the exact meaning of the data format for the particular operation is described. \n\n\nDimension GetInputDimension()\n\n\n\nGives a structure, Dimension, containing the dimension of the expected input data.\n\n\nIModelData GetSummary()\n\n\n\nGives an object of \nSequentialModelData\n type. Therefore it is necessary to cast the output for that type. SequentialModelData has the following methods to access information about the layers and the model:\n\n\nint GetNumberofLayers()\n\n\n\nGives the number of layers in the model. The InputLayer is not taken into account.\n\n\nstring GetLayerNameAt(int idx)\n\n\n\nGives the name of the layer at place \nidx\n. The counting starts at zero.\n\n\ndouble GetExecutionTime()\n\n\n\nGives the evaluation time of the network for one forward pass in \nmilli seconds\n.\n\n\nstring GetStringRepresentation()\n\n\n\nGives a string containing all the information of the layers.\n\n\nLayerData GetLayerDataAt(int idx)\n\n\n\nGives the LayerData for a concrete layer. LayerData contains the parameters of the input and the output data. The name of the layer is also available.\n\n\nGraph model",
            "title": "Models"
        },
        {
            "location": "/models/#models",
            "text": "",
            "title": "Models"
        },
        {
            "location": "/models/#interface-imodel",
            "text": "This is the interface for all of the models. It contains only one function which returns the structure of the model. This is important to get access to the model details.",
            "title": "Interface: IModel"
        },
        {
            "location": "/models/#sequential-model",
            "text": "[source]    \nThe smallest building block of the sequential model is the  layer . The layers are organised consequtively. The output of a layer is the input to the next layer.  NNSharp architecture is based on general descriptors of the possible operations (called kernels in this context) and then it applies a compiler to get the executable model. The compilation is done when a reader function (see Keras part for example) is called. The reader function reads the descriptors, builds a model then compiles it. After compilation calculations on new date reuires to call:  IData ExecuteNetwork(IData input)  Where IData can be a Data2D data type (or later Data3D). At the detailed descriptions the exact meaning of the data format for the particular operation is described.   Dimension GetInputDimension()  Gives a structure, Dimension, containing the dimension of the expected input data.  IModelData GetSummary()  Gives an object of  SequentialModelData  type. Therefore it is necessary to cast the output for that type. SequentialModelData has the following methods to access information about the layers and the model:  int GetNumberofLayers()  Gives the number of layers in the model. The InputLayer is not taken into account.  string GetLayerNameAt(int idx)  Gives the name of the layer at place  idx . The counting starts at zero.  double GetExecutionTime()  Gives the evaluation time of the network for one forward pass in  milli seconds .  string GetStringRepresentation()  Gives a string containing all the information of the layers.  LayerData GetLayerDataAt(int idx)  Gives the LayerData for a concrete layer. LayerData contains the parameters of the input and the output data. The name of the layer is also available.",
            "title": "Sequential model"
        },
        {
            "location": "/models/#graph-model",
            "text": "",
            "title": "Graph model"
        },
        {
            "location": "/data/",
            "text": "[source]\n \n\n\nData2D\n\n\n \n[source]\n \n\n\nDataArray\n\n\n \n[source]\n \n\n\nSequentialModelData",
            "title": "Data structure"
        },
        {
            "location": "/data/#data2d",
            "text": "[source]",
            "title": "Data2D"
        },
        {
            "location": "/data/#dataarray",
            "text": "[source]",
            "title": "DataArray"
        },
        {
            "location": "/data/#sequentialmodeldata",
            "text": "",
            "title": "SequentialModelData"
        },
        {
            "location": "/startkeras/",
            "text": "Getting Started with Keras models\n\n\nIf the training was done with Keras then the model can be saved by using the python script named \nKerasModeltoJSON.py\n. It will create a json file which can be read by NNSharp. NNSharp will build the model in C# and provides function to execute it. The python script takes the created and compiled Keras \nmodel\n and the \noutput file name\n as arguments. Then the json file can be created in the following way in your Python program:\n\n\nimport KerasModeltoJSON as js\nwrt = js.JSONwriter(model, file_path)\nwrt.save()\n\n\n\n\nThen in the C# program use the following:\n\n\n// Read the previously created json.\nvar reader = new ReaderKerasModel(filePath); \nSequentialModel model = reader.GetSequentialExecutor();\n\n// Then create the data to run the executer on.\n// batch: should be set in the Keras model.\nData2D input = new Data2D(height, width, channel, batch);\n\n// Calculate the network's output.\nIData output = model.ExecuteNetwork(input);\n\n\n\n\nIn order to know what data should be the \ninput\n and the \noutput\n see the corresponding documentations for the \nlayer at input\n and the \nlayer at output\n, respectively.",
            "title": "Quick start"
        },
        {
            "location": "/startkeras/#getting-started-with-keras-models",
            "text": "If the training was done with Keras then the model can be saved by using the python script named  KerasModeltoJSON.py . It will create a json file which can be read by NNSharp. NNSharp will build the model in C# and provides function to execute it. The python script takes the created and compiled Keras  model  and the  output file name  as arguments. Then the json file can be created in the following way in your Python program:  import KerasModeltoJSON as js\nwrt = js.JSONwriter(model, file_path)\nwrt.save()  Then in the C# program use the following:  // Read the previously created json.\nvar reader = new ReaderKerasModel(filePath); \nSequentialModel model = reader.GetSequentialExecutor();\n\n// Then create the data to run the executer on.\n// batch: should be set in the Keras model.\nData2D input = new Data2D(height, width, channel, batch);\n\n// Calculate the network's output.\nIData output = model.ExecuteNetwork(input);  In order to know what data should be the  input  and the  output  see the corresponding documentations for the  layer at input  and the  layer at output , respectively.",
            "title": "Getting Started with Keras models"
        },
        {
            "location": "/core/",
            "text": "The core layers contain layers to transform the shape of the input and the fully connected layer as a usual ingridient of a neural network. \n\n\n \n[source]\n \n\n\nFully connected (Dense layer)\n\n\nThe structure of \nFully connected layer\n can be seen on the following image:\n\n\n\n\nInput:\n\n\nA Data2D type with the shape: (1, 1, channels, batches).\n\n\nOutput:\n\n\nA Data2D type with the shape: (1, 1, units, batches).\n\n\nMethods:\n\n\nAs it can be seen on the picture this layer uses as many weight vectors (kernels) as many units have the layer. The number of units is equal with the number of output units. The fully connected layer is a linear transformation. A weight multiplies the corresponding input value (blue circle), then the output value (orange circle) is the sum of the previously weighted inputs. For further details see the source code where kernels are used in terms of units.\n\n\n \n[source]\n \n\n\nFlatten\n\n\nThe \nFlatten layer\n creates a 1-dimensional output (array) from the input. \n\n\nInput:\n\n\nA Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).\n\n\nOutput:\n\n\nA Data2D type data with the following shape: (1, 1, rows * columns * channels, batches). This represents a 1-dimensional vector.\n\n\nMethod:\n\n\nThe mapping occurs in the following way. The \nbatch\n remains unchanged. For a given \nbatch\n the reading order is: 1) channel, 2) column, 3) row. Therefore when \nrow\n and \ncolumn\n are fixed, \nchannel\n is changing. When \nchannel\n achieves its bound, \ncolumn\n is increased while \nrow\n is still fixed. Then \nchannel\n is iterated again and so on.\n\n\n \n[source]\n \n\n\nReshape2D\n\n\n(Next release)\n\n\nThe \nReshape2D layer\n creates an output with the prescribed shape.\n\n\nInput:\n\n\nA Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).\n\n\nOutput:\n\n\nA Data2D type data with the required (prescribed) shape.\n\n\nMethod:\n\n\nReshaping assumes a strict reading order for accessing all of the elements. It has the following priority regarding the dimensions: 1) channel, 2) column, 3) row, 4) batch. If the elements are accessed by this manner, a one dimensional array (let's call it \nvirtual array\n) will contain all the elements. The algorithm will reshape the original data into a new one that after using the same access method on it, the same virtual array would appear. (The same element in the original and the new data should be mapped to the same place in the virtual array by the access method.)\n\n\n \n[source]\n \n\n\nPermute\n\n\n(Next release)\n\n\nThe \nPermute layer\n creates an output with the same number of elements but the roles of the dimensions are changed.\n\n\nInput:\n\n\nA Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).\n\n\nOutput:\n\n\nA Data2D type data with permuted shape (new rows, new columns, new channels, batches). The \nbatches can not\n be changed by permutation. \n\n\nMethod:\n\n\nLet's suppose that the rows and channels are permuted in the output. Then an element in the input will be written to the permuted places as the example shows:\n\n\nIndicies in the input: h, w, c, b --> element = input[h, w, c, b].\nThen in the output data: output[c, w, h, b] = element.\n\n\n\n \n[source]\n \n\n\nRepeatVector\n\n\n(Next release)\n\n\nThe \nRepeatVector layer\n repeats a 1-dimensional vector n times.\n\n\nInput:\n\n\nA Data2D type data with shape: (1, 1, channels, batches).\n\n\nOutput:\n\n\nA Data2D type data with shape: (1, n, channels, batches).\n\n\nMethod:\n\n\nRepeats the same 1-dimensional input for each channel and batch. \n\n\n \n[source]\n \n\n\nBias\n\n\nThe \nBias layer\n adds bias values to the input data. Elements with the same channel are increased by the same bias value. The input and the output shapes \nare the same\n.\n\n\nInput:\n\n\nA Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).\n\n\nOutput:\n\n\nIt is the same as the input.\n\n\nMethod:\n\n\nAdding bias  means the following:\n\n\noutput[h, w, c, b] += input[h, w, c, b] + bias[c]",
            "title": "Core"
        },
        {
            "location": "/core/#fully-connected-dense-layer",
            "text": "The structure of  Fully connected layer  can be seen on the following image:   Input:  A Data2D type with the shape: (1, 1, channels, batches).  Output:  A Data2D type with the shape: (1, 1, units, batches).  Methods:  As it can be seen on the picture this layer uses as many weight vectors (kernels) as many units have the layer. The number of units is equal with the number of output units. The fully connected layer is a linear transformation. A weight multiplies the corresponding input value (blue circle), then the output value (orange circle) is the sum of the previously weighted inputs. For further details see the source code where kernels are used in terms of units.    [source]",
            "title": "Fully connected (Dense layer)"
        },
        {
            "location": "/core/#flatten",
            "text": "The  Flatten layer  creates a 1-dimensional output (array) from the input.   Input:  A Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).  Output:  A Data2D type data with the following shape: (1, 1, rows * columns * channels, batches). This represents a 1-dimensional vector.  Method:  The mapping occurs in the following way. The  batch  remains unchanged. For a given  batch  the reading order is: 1) channel, 2) column, 3) row. Therefore when  row  and  column  are fixed,  channel  is changing. When  channel  achieves its bound,  column  is increased while  row  is still fixed. Then  channel  is iterated again and so on.    [source]",
            "title": "Flatten"
        },
        {
            "location": "/core/#reshape2d",
            "text": "(Next release)  The  Reshape2D layer  creates an output with the prescribed shape.  Input:  A Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).  Output:  A Data2D type data with the required (prescribed) shape.  Method:  Reshaping assumes a strict reading order for accessing all of the elements. It has the following priority regarding the dimensions: 1) channel, 2) column, 3) row, 4) batch. If the elements are accessed by this manner, a one dimensional array (let's call it  virtual array ) will contain all the elements. The algorithm will reshape the original data into a new one that after using the same access method on it, the same virtual array would appear. (The same element in the original and the new data should be mapped to the same place in the virtual array by the access method.)    [source]",
            "title": "Reshape2D"
        },
        {
            "location": "/core/#permute",
            "text": "(Next release)  The  Permute layer  creates an output with the same number of elements but the roles of the dimensions are changed.  Input:  A Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).  Output:  A Data2D type data with permuted shape (new rows, new columns, new channels, batches). The  batches can not  be changed by permutation.   Method:  Let's suppose that the rows and channels are permuted in the output. Then an element in the input will be written to the permuted places as the example shows:  Indicies in the input: h, w, c, b --> element = input[h, w, c, b].\nThen in the output data: output[c, w, h, b] = element.    [source]",
            "title": "Permute"
        },
        {
            "location": "/core/#repeatvector",
            "text": "(Next release)  The  RepeatVector layer  repeats a 1-dimensional vector n times.  Input:  A Data2D type data with shape: (1, 1, channels, batches).  Output:  A Data2D type data with shape: (1, n, channels, batches).  Method:  Repeats the same 1-dimensional input for each channel and batch.     [source]",
            "title": "RepeatVector"
        },
        {
            "location": "/core/#bias",
            "text": "The  Bias layer  adds bias values to the input data. Elements with the same channel are increased by the same bias value. The input and the output shapes  are the same .  Input:  A Data2D type data with arbitrary shape (rows, columns, channels, batches can be anything).  Output:  It is the same as the input.  Method:  Adding bias  means the following:  output[h, w, c, b] += input[h, w, c, b] + bias[c]",
            "title": "Bias"
        },
        {
            "location": "/convolutions/",
            "text": "[source]\n \n\n\nConvolution1D\n\n\n \n[source]\n \n\n\nConvolution2D\n\n\n \n[source]\n \n\n\nCropping1D\n\n\n(Next release)\n\n\n \n[source]\n \n\n\nCropping2D\n\n\n(Next release)",
            "title": "Convolutions"
        },
        {
            "location": "/convolutions/#convolution1d",
            "text": "[source]",
            "title": "Convolution1D"
        },
        {
            "location": "/convolutions/#convolution2d",
            "text": "[source]",
            "title": "Convolution2D"
        },
        {
            "location": "/convolutions/#cropping1d",
            "text": "(Next release)    [source]",
            "title": "Cropping1D"
        },
        {
            "location": "/convolutions/#cropping2d",
            "text": "(Next release)",
            "title": "Cropping2D"
        },
        {
            "location": "/pooling/",
            "text": "[source]\n\n\nAveragePooling1D\n\n\n[source]\n\n\nAveragePooling2D\n\n\n[source]\n\n\nGlobalAveragePooling1D\n\n\n(Next release)\n\n\n[source]\n\n\nGlobalAveragePooling2D\n\n\n(Next release)\n\n\n[source]\n\n\nGlobalMaxPooling1D\n\n\n(Next release)\n\n\n[source]\n\n\nGlobalMaxPooling2D\n\n\n(Next release)\n\n\n[source]\n\n\nMaxPooling1D\n\n\n[source]\n\n\nMaxPooling2D",
            "title": "Pooling"
        },
        {
            "location": "/pooling/#averagepooling1d",
            "text": "[source]",
            "title": "AveragePooling1D"
        },
        {
            "location": "/pooling/#averagepooling2d",
            "text": "[source]",
            "title": "AveragePooling2D"
        },
        {
            "location": "/pooling/#globalaveragepooling1d",
            "text": "(Next release)  [source]",
            "title": "GlobalAveragePooling1D"
        },
        {
            "location": "/pooling/#globalaveragepooling2d",
            "text": "(Next release)  [source]",
            "title": "GlobalAveragePooling2D"
        },
        {
            "location": "/pooling/#globalmaxpooling1d",
            "text": "(Next release)  [source]",
            "title": "GlobalMaxPooling1D"
        },
        {
            "location": "/pooling/#globalmaxpooling2d",
            "text": "(Next release)  [source]",
            "title": "GlobalMaxPooling2D"
        },
        {
            "location": "/pooling/#maxpooling1d",
            "text": "[source]",
            "title": "MaxPooling1D"
        },
        {
            "location": "/pooling/#maxpooling2d",
            "text": "",
            "title": "MaxPooling2D"
        },
        {
            "location": "/activations/",
            "text": "Activation functions are applied in an element-wise maner on the input. \nTherefore the dimension of the input and output is the same.\n The goal of the activation functions is to break the linearity of the network. This can provide a function space (in terms of the trainable weights) which can approximate a large body of mapping rules from the inputs to the outputs. For mathematical details see the following references: \n\n\n\n\nFunahashi, K. I. \"On the Approximate Realization of Continuous Mappings by Neural Networks\", Neural Networks, Vol. 2. No. 3. pp. 183-192. 1989.\n\n\nLeshno, M. - Lin, V. Y. - Pinkus, A. - Schocken, S. \"Multilayer Feedforward Networks With a Nonpolynomial Activation Function Can Approximate Any Function\", Neural Networks, Vol. 6. pp. 861-867. 1993.\n\n\n\n\nThe last one contains the following \ntheorem\n:\n\n\nAssume the neural network contains one non-linear layer. An \nf\n  function (domain and range are real numbers) can be approximated with arbitrary accuracy if and only if the applied activation function is not a polynom and it is locally bounded.\n\n\n \n[source]\n \n\n\nELu\n\n\n\n\n \n[source]\n \n\n\nHardSigmoid\n\n\n\n\n \n[source]\n \n\n\nReLu\n\n\n\n\n \n[source]\n \n\n\nSigmoid\n\n\n\n\n \n[source]\n \n\n\nSoftPlus\n\n\n\n\n \n[source]\n \n\n\nSoftmax\n\n\n \n[source]\n \n\n\nSoftsign\n\n\n\n\n \n[source]\n \n\n\nTanH",
            "title": "Activations"
        },
        {
            "location": "/activations/#elu",
            "text": "[source]",
            "title": "ELu"
        },
        {
            "location": "/activations/#hardsigmoid",
            "text": "[source]",
            "title": "HardSigmoid"
        },
        {
            "location": "/activations/#relu",
            "text": "[source]",
            "title": "ReLu"
        },
        {
            "location": "/activations/#sigmoid",
            "text": "[source]",
            "title": "Sigmoid"
        },
        {
            "location": "/activations/#softplus",
            "text": "[source]",
            "title": "SoftPlus"
        },
        {
            "location": "/activations/#softmax",
            "text": "[source]",
            "title": "Softmax"
        },
        {
            "location": "/activations/#softsign",
            "text": "[source]",
            "title": "Softsign"
        },
        {
            "location": "/activations/#tanh",
            "text": "",
            "title": "TanH"
        },
        {
            "location": "/recurrents/",
            "text": "[source]\n\n\nSimpleRNN\n\n\n(Next release)",
            "title": "Recurrent layers"
        },
        {
            "location": "/recurrents/#simplernn",
            "text": "(Next release)",
            "title": "SimpleRNN"
        },
        {
            "location": "/batchnormalization/",
            "text": "[source]\n \n\n\nBatch Normalization\n\n\n(Next release)",
            "title": "BatchNormalization"
        },
        {
            "location": "/batchnormalization/#batch-normalization",
            "text": "(Next release)",
            "title": "Batch Normalization"
        },
        {
            "location": "/starttensorflow/",
            "text": "",
            "title": "Quick start"
        }
    ]
}