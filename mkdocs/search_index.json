{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to NNSharp\n\n\nThis is the full documentation of NNSharp which is a lightweight library for running pre-trained neural networks. The training should be done in \nKeras\n, \nTensorFlow\n, \nPytorch\n or \nSonnet\n then the weights and the network architecture should be saved into a file (json). NNSharp is able to read and run the network especially on Windows and Visual Studio. \n\n\nCurrent abilities\n\n\nNNSharp recently supports Keras models with both Tensorflow and Theano backend. The list of the supported \nKeras layers\n:\n\n\n\n\nCore layers\n: Dense, Reshape (2D), Permute, RepeatVector. \n\n\nConvolution layers\n: Conv1D, Conv2D, Cropping1D, Cropping2D. \n\n\nPooling layers\n: AveragePooling1D, AveragePooling2D, MaxPooling1D, MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D.\n\n\nActivations\n: softmax, elu, softplus, softsign, relu, tanh, sigmoid, hard_sigmoid. \n\n\nNormalization\n: BatchNormalization.\n\n\n\n\nThe \ndata format\n supports 2-dimensional data. \n\n\nThe structure of the documentation\n\n\nThe purpose of the documentation is twofold:\n\n\n\n\nAs a user guide to show how to use the package.\n\n\nProviding some further insight how the kernels work in a concise manner. Therefore developers and researchers can immediately understand what the kernel does without inspecting the code or looking for other sources on the net. This can be helpful for contributors as a developer documentation. On the other hand users can understand what to feed into the network and how to use (and construct) the output.\n\n\n\n\nThe structure of the documentation is the following:\n\n\n\n\nInstallation\n shows how to get access to the package.\n\n\nModels\n introduces the model types and methods to access information about the model like the contained layers or nodes, execution time etc.\n\n\nKeras\n shows the implemented Keras layers. Each layer introduced with its input, output and its underlying process.\n\n\nTensorFlow\n shows how to use pre-trained TensorFlow models in NNSharp.\n\n\n\n\nFuture\n\n\nIn the future the library should provide the following features:\n\n\n\n\nSupports the whole Keras API.\n\n\nSupports TensorFlow models.\n\n\nSupports PyTorch regarding neural netowrks.\n\n\nSupports Sonnet.\n\n\nMulti-threading for faster kernels.\n\n\nKeras-like API over TensorFlow for building, training and running networks. This requires an extended C++ API in TensorFlow and reliable compilation for Windows.\n\n\n\n\nContributions are always welcomed! For the current purposes see the \ngithub repository\n of the project.",
            "title": "Overview"
        },
        {
            "location": "/#welcome-to-nnsharp",
            "text": "This is the full documentation of NNSharp which is a lightweight library for running pre-trained neural networks. The training should be done in  Keras ,  TensorFlow ,  Pytorch  or  Sonnet  then the weights and the network architecture should be saved into a file (json). NNSharp is able to read and run the network especially on Windows and Visual Studio.",
            "title": "Welcome to NNSharp"
        },
        {
            "location": "/#current-abilities",
            "text": "NNSharp recently supports Keras models with both Tensorflow and Theano backend. The list of the supported  Keras layers :   Core layers : Dense, Reshape (2D), Permute, RepeatVector.   Convolution layers : Conv1D, Conv2D, Cropping1D, Cropping2D.   Pooling layers : AveragePooling1D, AveragePooling2D, MaxPooling1D, MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D.  Activations : softmax, elu, softplus, softsign, relu, tanh, sigmoid, hard_sigmoid.   Normalization : BatchNormalization.   The  data format  supports 2-dimensional data.",
            "title": "Current abilities"
        },
        {
            "location": "/#the-structure-of-the-documentation",
            "text": "The purpose of the documentation is twofold:   As a user guide to show how to use the package.  Providing some further insight how the kernels work in a concise manner. Therefore developers and researchers can immediately understand what the kernel does without inspecting the code or looking for other sources on the net. This can be helpful for contributors as a developer documentation. On the other hand users can understand what to feed into the network and how to use (and construct) the output.   The structure of the documentation is the following:   Installation  shows how to get access to the package.  Models  introduces the model types and methods to access information about the model like the contained layers or nodes, execution time etc.  Keras  shows the implemented Keras layers. Each layer introduced with its input, output and its underlying process.  TensorFlow  shows how to use pre-trained TensorFlow models in NNSharp.",
            "title": "The structure of the documentation"
        },
        {
            "location": "/#future",
            "text": "In the future the library should provide the following features:   Supports the whole Keras API.  Supports TensorFlow models.  Supports PyTorch regarding neural netowrks.  Supports Sonnet.  Multi-threading for faster kernels.  Keras-like API over TensorFlow for building, training and running networks. This requires an extended C++ API in TensorFlow and reliable compilation for Windows.   Contributions are always welcomed! For the current purposes see the  github repository  of the project.",
            "title": "Future"
        },
        {
            "location": "/install/",
            "text": "Installation\n\n\nNNSharp is available as a \nnuget package\n. It was built on Visual Studio 2015 with .NET Framework 4.5.2. The easiest way to install is to use the \nnuget package manager\n in Visual Studio. As an other option the necessary dll can be built from the source code (\ndownload link\n). The current release is the v1.1. It has only one dependency: \nNewtonsoft.Json\n.",
            "title": "Installation"
        },
        {
            "location": "/install/#installation",
            "text": "NNSharp is available as a  nuget package . It was built on Visual Studio 2015 with .NET Framework 4.5.2. The easiest way to install is to use the  nuget package manager  in Visual Studio. As an other option the necessary dll can be built from the source code ( download link ). The current release is the v1.1. It has only one dependency:  Newtonsoft.Json .",
            "title": "Installation"
        },
        {
            "location": "/models/",
            "text": "Models\n\n\nInterface: IModel\n\n\nThis is the interface for all of the models. It contains only one function which returns the structure of the model. This is important to get access to the model details.\n\n\nSequential model\n\n\n \n[source]\n \n\n\n\nThe smallest building block of the sequential model is the \nlayer\n. The layers are organised consequtively. The output of a layer is the input to the next layer.\n\n\nNNSharp architecture is based on general descriptors of the possible operations (called kernels in this context) and then it applies a compiler to get the executable model. The compilation is done when a reader function (see Keras part for example) is called. The reader function reads the descriptors, builds a model then compiles it. After compilation calculations on new date reuires to call:\n\n\nIData ExecuteNetwork(IData input)\n\n\n\nWhere IData can be a Data2D data type (or later Data3D). At the detailed descriptions the exact meaning of the data format for the particular operation is described. \n\n\nDimension GetInputDimension()\n\n\n\nGives a structure, Dimension, containing the dimension of the expected input data.\n\n\nIModelData GetSummary()\n\n\n\nGives an object of \nSequentialModelData\n type. Therefore it is necessary to cast the output for that type. SequentialModelData has the following methods to access information about the layers and the model:\n\n\nint GetNumberofLayers()\n\n\n\nGives the number of layers in the model. The InputLayer is not taken into account.\n\n\nstring GetLayerNameAt(int idx)\n\n\n\nGives the name of the layer at place \nidx\n. The counting starts at zero.\n\n\ndouble GetExecutionTime()\n\n\n\nGives the evaluation time of the network for one forward pass in \nmilli seconds\n.\n\n\nstring GetStringRepresentation()\n\n\n\nGives a string containing all the information of the layers.\n\n\nLayerData GetLayerDataAt(int idx)\n\n\n\nGives the LayerData for a concrete layer. LayerData contains the parameters of the input and the output data. The name of the layer is also available.\n\n\nGraph model",
            "title": "Models"
        },
        {
            "location": "/models/#models",
            "text": "",
            "title": "Models"
        },
        {
            "location": "/models/#interface-imodel",
            "text": "This is the interface for all of the models. It contains only one function which returns the structure of the model. This is important to get access to the model details.",
            "title": "Interface: IModel"
        },
        {
            "location": "/models/#sequential-model",
            "text": "[source]    \nThe smallest building block of the sequential model is the  layer . The layers are organised consequtively. The output of a layer is the input to the next layer.  NNSharp architecture is based on general descriptors of the possible operations (called kernels in this context) and then it applies a compiler to get the executable model. The compilation is done when a reader function (see Keras part for example) is called. The reader function reads the descriptors, builds a model then compiles it. After compilation calculations on new date reuires to call:  IData ExecuteNetwork(IData input)  Where IData can be a Data2D data type (or later Data3D). At the detailed descriptions the exact meaning of the data format for the particular operation is described.   Dimension GetInputDimension()  Gives a structure, Dimension, containing the dimension of the expected input data.  IModelData GetSummary()  Gives an object of  SequentialModelData  type. Therefore it is necessary to cast the output for that type. SequentialModelData has the following methods to access information about the layers and the model:  int GetNumberofLayers()  Gives the number of layers in the model. The InputLayer is not taken into account.  string GetLayerNameAt(int idx)  Gives the name of the layer at place  idx . The counting starts at zero.  double GetExecutionTime()  Gives the evaluation time of the network for one forward pass in  milli seconds .  string GetStringRepresentation()  Gives a string containing all the information of the layers.  LayerData GetLayerDataAt(int idx)  Gives the LayerData for a concrete layer. LayerData contains the parameters of the input and the output data. The name of the layer is also available.",
            "title": "Sequential model"
        },
        {
            "location": "/models/#graph-model",
            "text": "",
            "title": "Graph model"
        },
        {
            "location": "/startkeras/",
            "text": "Getting Started with Keras models\n\n\nIf the training was done with Keras then the model can be saved by using the python script named \nKerasModeltoJSON.py\n. It will create a json file which can be read by NNSharp. NNSharp will build the model in C# and provides function to execute it. The python script takes the created and compiled Keras \nmodel\n and the \noutput file name\n as arguments. Then the json file can be created in the following way in your Python program:\n\n\nimport KerasModeltoJSON as js\nwrt = js.JSONwriter(model, file_path)\nwrt.save()\n\n\n\n\nThen in the C# program use the following:\n\n\n// Read the previously created json.\nvar reader = new ReaderKerasModel(filePath); \nSequentialModel model = reader.GetSequentialExecutor();\n\n// Then create the data to run the executer on.\n// batch: should be set in the Keras model.\nData2D input = new Data2D(height, width, channel, batch);\n\n// Calculate the network's output.\nIData output = model.ExecuteNetwork(input);\n\n\n\n\nIn order to know what data should be the \ninput\n and the \noutput\n see the corresponding documentations for the \nlayer at input\n and the \nlayer at output\n, respectively.",
            "title": "Quick start"
        },
        {
            "location": "/startkeras/#getting-started-with-keras-models",
            "text": "If the training was done with Keras then the model can be saved by using the python script named  KerasModeltoJSON.py . It will create a json file which can be read by NNSharp. NNSharp will build the model in C# and provides function to execute it. The python script takes the created and compiled Keras  model  and the  output file name  as arguments. Then the json file can be created in the following way in your Python program:  import KerasModeltoJSON as js\nwrt = js.JSONwriter(model, file_path)\nwrt.save()  Then in the C# program use the following:  // Read the previously created json.\nvar reader = new ReaderKerasModel(filePath); \nSequentialModel model = reader.GetSequentialExecutor();\n\n// Then create the data to run the executer on.\n// batch: should be set in the Keras model.\nData2D input = new Data2D(height, width, channel, batch);\n\n// Calculate the network's output.\nIData output = model.ExecuteNetwork(input);  In order to know what data should be the  input  and the  output  see the corresponding documentations for the  layer at input  and the  layer at output , respectively.",
            "title": "Getting Started with Keras models"
        },
        {
            "location": "/core/",
            "text": "The core layers contains layers to transform the shape of the input and the fully connected layer as a usual ingridient of a neural networks. \n\n\n \n[source]\n \n\n\nFully connected (Dense layer)\n\n\n \n[source]\n \n\n\nFlatten\n\n\n \n[source]\n \n\n\nReshape2D\n\n\n \n[source]\n \n\n\nPermute\n\n\n \n[source]\n \n\n\nRepeatVector\n\n\n \n[source]\n \n\n\nBias",
            "title": "Core"
        },
        {
            "location": "/core/#fully-connected-dense-layer",
            "text": "[source]",
            "title": "Fully connected (Dense layer)"
        },
        {
            "location": "/core/#flatten",
            "text": "[source]",
            "title": "Flatten"
        },
        {
            "location": "/core/#reshape2d",
            "text": "[source]",
            "title": "Reshape2D"
        },
        {
            "location": "/core/#permute",
            "text": "[source]",
            "title": "Permute"
        },
        {
            "location": "/core/#repeatvector",
            "text": "[source]",
            "title": "RepeatVector"
        },
        {
            "location": "/core/#bias",
            "text": "",
            "title": "Bias"
        },
        {
            "location": "/convolutions/",
            "text": "[source]\n \n\n\nConvolution1D\n\n\nThe convolution...\n\n\n \n[source]\n \n\n\nConvolution2D\n\n\n \n[source]\n \n\n\nCropping1D\n\n\n \n[source]\n \n\n\nCropping2D",
            "title": "Convolutions"
        },
        {
            "location": "/convolutions/#convolution1d",
            "text": "The convolution...    [source]",
            "title": "Convolution1D"
        },
        {
            "location": "/convolutions/#convolution2d",
            "text": "[source]",
            "title": "Convolution2D"
        },
        {
            "location": "/convolutions/#cropping1d",
            "text": "[source]",
            "title": "Cropping1D"
        },
        {
            "location": "/convolutions/#cropping2d",
            "text": "",
            "title": "Cropping2D"
        },
        {
            "location": "/pooling/",
            "text": "[source]\n\n\nAveragePooling1D\n\n\n[source]\n\n\nAveragePooling2D\n\n\n[source]\n\n\nGlobalAveragePooling1D\n\n\n[source]\n\n\nGlobalAveragePooling2D\n\n\n[source]\n\n\nGlobalMaxPooling1D\n\n\n[source]\n\n\nGlobalMaxPooling2D\n\n\n[source]\n\n\nMaxPooling1D\n\n\n[source]\n\n\nMaxPooling2D",
            "title": "Pooling"
        },
        {
            "location": "/pooling/#averagepooling1d",
            "text": "[source]",
            "title": "AveragePooling1D"
        },
        {
            "location": "/pooling/#averagepooling2d",
            "text": "[source]",
            "title": "AveragePooling2D"
        },
        {
            "location": "/pooling/#globalaveragepooling1d",
            "text": "[source]",
            "title": "GlobalAveragePooling1D"
        },
        {
            "location": "/pooling/#globalaveragepooling2d",
            "text": "[source]",
            "title": "GlobalAveragePooling2D"
        },
        {
            "location": "/pooling/#globalmaxpooling1d",
            "text": "[source]",
            "title": "GlobalMaxPooling1D"
        },
        {
            "location": "/pooling/#globalmaxpooling2d",
            "text": "[source]",
            "title": "GlobalMaxPooling2D"
        },
        {
            "location": "/pooling/#maxpooling1d",
            "text": "[source]",
            "title": "MaxPooling1D"
        },
        {
            "location": "/pooling/#maxpooling2d",
            "text": "",
            "title": "MaxPooling2D"
        },
        {
            "location": "/activations/",
            "text": "Activation functions are applied in an element-wise maner on the input. \nTherefore the dimension of the input and output is the same.\n The goal of the activation functions is to break the linearity of the network. This can provide a function space (in terms of the trainable weights) which can approximate a large body of mapping rules from the inputs to the outputs. For mathematical details see the following references: \n\n\n\n\nFunahashi, K. I. \"On the Approximate Realization of Continuous Mappings by Neural Networks\", Neural Networks, Vol. 2. No. 3. pp. 183-192. 1989.\n\n\nLeshno, M. - Lin, V. Y. - Pinkus, A. - Schocken, S. \"Multilayer Feedforward Networks With a Nonpolynomial Activation Function Can Approximate Any Function\", Neural Networks, Vol. 6. pp. 861-867. 1993.\n\n\n\n\nThe last one contains the following \ntheorem\n:\n\n\nAssume the neural network contains one non-linear layer. An \nf\n  function (domain and range are real numbers) can be approximated with arbitrary accuracy if and only if the applied activation function is not a polynom and it is locally bounded.\n\n\n \n[source]\n \n\n\nELu\n\n\n\n\n \n[source]\n \n\n\nHardSigmoid\n\n\n\n\n \n[source]\n \n\n\nReLu\n\n\n\n\n \n[source]\n \n\n\nSigmoid\n\n\n\n\n \n[source]\n \n\n\nSoftPlus\n\n\n\n\n \n[source]\n \n\n\nSoftmax\n\n\n \n[source]\n \n\n\nSoftsign\n\n\n\n\n \n[source]\n \n\n\nTanH",
            "title": "Activations"
        },
        {
            "location": "/activations/#elu",
            "text": "[source]",
            "title": "ELu"
        },
        {
            "location": "/activations/#hardsigmoid",
            "text": "[source]",
            "title": "HardSigmoid"
        },
        {
            "location": "/activations/#relu",
            "text": "[source]",
            "title": "ReLu"
        },
        {
            "location": "/activations/#sigmoid",
            "text": "[source]",
            "title": "Sigmoid"
        },
        {
            "location": "/activations/#softplus",
            "text": "[source]",
            "title": "SoftPlus"
        },
        {
            "location": "/activations/#softmax",
            "text": "[source]",
            "title": "Softmax"
        },
        {
            "location": "/activations/#softsign",
            "text": "[source]",
            "title": "Softsign"
        },
        {
            "location": "/activations/#tanh",
            "text": "",
            "title": "TanH"
        },
        {
            "location": "/recurrents/",
            "text": "[source]\n\n\nSimpleRNN",
            "title": "Recurrent layers"
        },
        {
            "location": "/recurrents/#simplernn",
            "text": "",
            "title": "SimpleRNN"
        },
        {
            "location": "/batchnormalization/",
            "text": "[source]\n \n\n\nBatch Normalization",
            "title": "BatchNormalization"
        },
        {
            "location": "/batchnormalization/#batch-normalization",
            "text": "",
            "title": "Batch Normalization"
        },
        {
            "location": "/starttensorflow/",
            "text": "",
            "title": "Quick start"
        }
    ]
}